{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec2d7ba-2382-49dd-8f14-b8d2b06db905",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use Intel's Neural Coder to Automate Alibaba PAI BladeDISC Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26896e2-7c66-41d0-94f7-d222f042f779",
   "metadata": {},
   "source": [
    "### What is Neural Coder\n",
    "Neural Coder is a sub-component under Intel Neural Compressor. It simplifies deployment of deep learning (DL) models via one-click, automated code changes (e.g., to switch accelerator devices or enable optimizations). It uses static program analysis and heuristics to help users take advantage of Intel DL Boost and hardware features to improve performance. This one-click enabling boosts developer productivity while making it easier to take advantage of acceleration. This can all be done through a convenient JupyterLab GUI extension to Neural Coder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f78fab-4b0b-4d5f-b257-3c384fdafbb8",
   "metadata": {},
   "source": [
    "Neural Coder has been integrated into PAI-DSW, and includes BladeDISC as one of its optimization backends. This simplifies access to the inference acceleration that BladeDISC provides. For example, the DL script of Hugging Face’s Albert Model can be one-click optimized using the “Alibaba Blade-DISC” option of the Neural Coder extension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a291d53-3055-476e-b718-19cbe4e6a0bd",
   "metadata": {},
   "source": [
    "### How to use Neural Coder extension in DSW\n",
    "Users can simply enable Neural Coder extension in DSW platform and use it according to this detailed [guidance](https://medium.com/intel-analytics-software/alibaba-cloud-collaborates-with-intel-neural-compressor-for-better-productivity-and-performance-83cdb6500420). Please have a try on the below code and test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6991b8-c5b7-45e4-8f80-454dd23e7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_test_data(batch_size, seq_len):\n",
    "    inp_ids = torch.zeros([batch_size, seq_len], dtype=torch.int)\n",
    "    inp_mask0 = torch.zeros([batch_size, seq_len], dtype=torch.int)\n",
    "    inp_mask1 = torch.zeros([batch_size, seq_len], dtype=torch.int)\n",
    "    return (inp_ids.to(torch.int32), inp_mask0.to(torch.int32), inp_mask1.to(torch.int32))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model\n",
    "    from transformers import AlbertModel\n",
    "    model = AlbertModel.from_pretrained(\"albert-base-v2\", torchscript=True)\n",
    "    model.eval()\n",
    "\n",
    "    # inputs\n",
    "    batch_size = 1\n",
    "    seq_len = 24\n",
    "    inputs = get_test_data(batch_size, seq_len)\n",
    "\n",
    "    # inference\n",
    "    with torch.no_grad():\n",
    "        model(*inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391246a6-6014-45fb-8ae4-5792cb31852b",
   "metadata": {},
   "source": [
    "After executing Neural Coder extension, you can see that the below optimization has been added to this code snippet:\n",
    "```python\n",
    "import torch_blade\n",
    "with torch.no_grad():\n",
    "    model = torch_blade.optimize(model, allow_tracing=True, model_inputs=inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffa41a-ece1-432b-a86a-093e06d424d8",
   "metadata": {},
   "source": [
    "Neural Coder will keep supporting more optimization APIs in the future for Alibaba PAI DSW. Keep in touch!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
